{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy.io as io\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "    json_file = open('/data/crowd_counting/models/Model_B.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(\"/data/crowd_counting/weights/model_B_weights.h5\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img(path):\n",
    "    #Function to load,normalize and return image \n",
    "    im = Image.open(path)\n",
    "    im = np.array(im)\n",
    "    \n",
    "    im = im/255.0\n",
    "    \n",
    "    im[:,:,0]=(im[:,:,0]-0.485)/0.229\n",
    "    im[:,:,1]=(im[:,:,1]-0.456)/0.224\n",
    "    im[:,:,2]=(im[:,:,2]-0.406)/0.225\n",
    "\n",
    "    im = np.expand_dims(im, axis = 0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/crowd_counting/ShanghaiTech/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_A_train = os.path.join(root,'part_A/train_data','images')\n",
    "part_A_test = os.path.join(root,'part_A/test_data','images')\n",
    "part_B_train = os.path.join(root,'part_B/train_data','images')\n",
    "part_B_test = os.path.join(root,'part_B/test_data','images')\n",
    "path_sets = [part_B_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316\n"
     ]
    }
   ],
   "source": [
    "img_paths = []\n",
    "for path in path_sets:\n",
    "    for img_path in glob.glob(os.path.join(path, '*.jpg')):\n",
    "        img_paths.append(img_path)\n",
    "print(len(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = load_model()\n",
    "name = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n",
    "for image in img_paths:\n",
    "    name.append(image)\n",
    "    gt = h5py.File(image.replace('.jpg','.h5').replace('images','ground') )\n",
    "    groundtruth = np.asarray(gt['density'])\n",
    "    num1 = np.sum(groundtruth)\n",
    "    y_true.append(np.sum(num1))\n",
    "    img = create_img(image)\n",
    "    num = np.sum(model.predict(img))\n",
    "    y_pred.append(np.sum(num)/64)  # account for scale in training\n",
    "\n",
    "    \n",
    "data = pd.DataFrame({'name': name,'y_pred': y_pred,'y_true': y_true})\n",
    "data.to_csv('CSV/B_on_B_test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_true[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CSV/B_on_B_test.csv')\n",
    "y_true = data['y_true']\n",
    "y_pred = data['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = mean_absolute_error(np.array(y_true),np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  10.24077465262594\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE : \" , ans )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('CSV/B_on_A_test.csv' , sep='\\t')\n",
    "# y_true = data['y_true']\n",
    "# y_pred = data['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans = mean_absolute_error(np.array(y_true),np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"MAE : \" , ans )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
